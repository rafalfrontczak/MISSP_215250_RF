{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic\n\nDoing feature engineering in the example of Titanic problem.\nTo learn more and join the competition by click [here](https://www.kaggle.com/c/titanic/)\n"},{"metadata":{},"cell_type":"markdown","source":"First we'll import the packages we need."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"1. I've alredy downloaded the data. Now let's read it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/titanic/train.csv')\n# PassengerId column is not something to learn on\ndata.drop(columns=['PassengerId'], inplace=True)\ntest = pd.read_csv('../input/titanic/test.csv')\ntest.drop(columns=['PassengerId'], inplace=True)\nX = data.drop(columns=['Survived'])\n# Survived column is what will be predicting\nY = data['Survived']","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some categorical features that have too many different values, let's find them out."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(X.columns)):\n    print(X.iloc[:, i].value_counts(), end='\\n\\n')","execution_count":3,"outputs":[{"output_type":"stream","text":"3    491\n1    216\n2    184\nName: Pclass, dtype: int64\n\nSage, Mr. Frederick                                          1\nGoldsmith, Mr. Frank John                                    1\nAndersson, Miss. Sigrid Elisabeth                            1\nGraham, Mrs. William Thompson (Edith Junkins)                1\nNankoff, Mr. Minko                                           1\n                                                            ..\nBostandyeff, Mr. Guentcho                                    1\nCalic, Mr. Petar                                             1\nBirkeland, Mr. Hans Martin Monsen                            1\nSirayanian, Mr. Orsen                                        1\nAsplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)    1\nName: Name, Length: 891, dtype: int64\n\nmale      577\nfemale    314\nName: Sex, dtype: int64\n\n24.00    30\n22.00    27\n18.00    26\n19.00    25\n30.00    25\n         ..\n55.50     1\n70.50     1\n66.00     1\n23.50     1\n0.42      1\nName: Age, Length: 88, dtype: int64\n\n0    608\n1    209\n2     28\n4     18\n3     16\n8      7\n5      5\nName: SibSp, dtype: int64\n\n0    678\n1    118\n2     80\n5      5\n3      5\n4      4\n6      1\nName: Parch, dtype: int64\n\n347082      7\nCA. 2343    7\n1601        7\n3101295     6\n347088      6\n           ..\n349252      1\n367655      1\n347468      1\n348121      1\n315088      1\nName: Ticket, Length: 681, dtype: int64\n\n8.0500     43\n13.0000    42\n7.8958     38\n7.7500     34\n26.0000    31\n           ..\n8.4583      1\n9.8375      1\n8.3625      1\n14.1083     1\n17.4000     1\nName: Fare, Length: 248, dtype: int64\n\nG6             4\nC23 C25 C27    4\nB96 B98        4\nE101           3\nC22 C26        3\n              ..\nD50            1\nE31            1\nD56            1\nE12            1\nC106           1\nName: Cabin, Length: 147, dtype: int64\n\nS    644\nC    168\nQ     77\nName: Embarked, dtype: int64\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"1.  These columns are ***Ticket***, ***Name*** and ***Cabin***."},{"metadata":{},"cell_type":"markdown","source":"Let's minimize the value counts of ***Ticket*** by the first letter of it's last word. This will give us some information on ticket's class."},{"metadata":{"trusted":true},"cell_type":"code","source":"X['Ticket'] = X['Ticket'].apply(lambda s:  str(s.split()[-1][0]))\ntest['Ticket'] = test['Ticket'].apply(lambda s:  str(s.split()[-1][0]))","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Full name doesn't give us much of an information. Let's trim it to just surname"},{"metadata":{"trusted":true},"cell_type":"code","source":"X['Name'] = X['Name'].apply(lambda s: s.split(',')[0])\ntest['Name'] = test['Name'].apply(lambda s: s.split(',')[0])","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's also take into account the number of people that have the same surname, as this will probably indicate the size of the family."},{"metadata":{"trusted":true},"cell_type":"code","source":"XNamevalue_counts = X['Name'].value_counts()\ntestNamevalue_counts = test['Name'].value_counts()\ndef GetFamilySize(name):\n    family_size = 0\n    try:\n        family_size += XNamevalue_counts[name]\n    finally:\n        try:\n            family_size += testNamevalue_counts[name]\n        finally:\n            return family_size\nX['Family_size'] = X['Name'].apply(lambda s: GetFamilySize(s))\ntest['Family_size'] = test['Name'].apply(lambda s: GetFamilySize(s))","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's categorize the ***Cabins*** too, by taking their first letter."},{"metadata":{"trusted":true},"cell_type":"code","source":"X['Cabin'] = X['Cabin'].apply(lambda s: str(s)[0])\ntest['Cabin'] = test['Cabin'].apply(lambda s: str(s)[0])","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some missing values for ***Age*** both in training, and in testing datasets. Let's impute them by taking the mean over the all ages we have (ages of both training and testing)."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_size_age = X.shape[0] - X['Age'].isna().sum()\ntest_size_age = test.shape[0] - test['Age'].isna().sum()\nmean_age = (X_size_age * X['Age'].mean() + \n            test_size_age * test['Age'].mean()) / \\\n            (X_size_age + test_size_age)\nX['Age'].fillna(mean_age, inplace=True)\ntest['Age'].fillna(mean_age, inplace=True)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's a missing value for ***Fare*** in testing dataset. Let's impute it the same way."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_size_fare = X.shape[0] - X['Fare'].isna().sum()\ntest_size_fare = test.shape[0] - test['Fare'].isna().sum()\nmean_fare = (X_size_fare * X['Fare'].mean() + \n            test_size_fare * test['Fare'].mean()) / \\\n            (X_size_fare + test_size_fare)\ntest['Fare'].fillna(mean_fare, inplace=True)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since sklearn works with only numerical values, we need to do one hot encoding for non-numerical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_dum = pd.get_dummies(X, drop_first=True)\nX_test_dum = pd.get_dummies(test, drop_first=True)\nX_dum.shape , X_test_dum.shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"((891, 692), (418, 375))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We only need columns if they are contained both in testing and training datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# symetric difference:\n# the columns that are not contained either in training or in testing datasets\nunnecesarry_columns = X_test_dum.columns ^ X_dum.columns\n# this are the columns that exist in testing dataset, but not in training\nunnecesarry_columns_X_dum = unnecesarry_columns & X_dum.columns \n# this are the columns that exist in training dataset, but not in testing\nunnecesarry_columns_X_test_dum = unnecesarry_columns & X_test_dum.columns\nX_dum = X_dum.drop(columns=unnecesarry_columns_X_dum)\nX_test_dum = X_test_dum.drop(columns=unnecesarry_columns_X_test_dum)\n# after this training and testing datasets should have the same columns\nall(X_dum.columns == X_test_dum.columns)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"To fight data imbalance let's oversample the minority class considering the Survived column."},{"metadata":{"trusted":true},"cell_type":"code","source":"ros = RandomOverSampler()\nA, B = ros.fit_resample(X_dum, Y)\nX_ros = pd.DataFrame(A, columns=X_dum.columns)\nY_ros = pd.Series(B)","execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'RandomOverSampler' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-36c360c42b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_ros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_dum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_ros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'RandomOverSampler' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"In case you want to hyperparameter tuning you can split the data into training and validation sets like this."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_ros,\n                                                  Y_ros,\n                                                  test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to fit a model to out data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rf = RandomForestClassifier(criterion='gini', n_estimators=121, \n                                  max_features=80, random_state=18)\nmodel_rf.fit(X_ros, Y_ros)\nprint('accuracy: ', accuracy_score(model_rf.predict(X_ros), Y_ros))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can finally evaluate the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rf = pd.DataFrame({'PassengerId' : np.arange(len(X_test_dum)) + 892,\n                        'Survived': model_rf.predict(X_test_dum)})\npred_rf.to_csv('pred_rf.csv', index=False)\npred_rf","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}